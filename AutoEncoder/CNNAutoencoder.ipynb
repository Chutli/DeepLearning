{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"demo3_CNNAutoencoder.ipynb","provenance":[],"authorship_tag":"ABX9TyOoqYtS16Yx5/OJ/QetazH/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Chapter 8: CNN Auto Encoder"],"metadata":{"id":"4rwcFdAI6E6v"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B8BF_p6-5-Ke","executionInfo":{"status":"ok","timestamp":1654925113002,"user_tz":-420,"elapsed":19078,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}},"outputId":"5f3ec7d9-5fb5-4b86-e0c6-b787d75c99fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/LDS8_K275_ONLINE_NGUYENTHIKIMHOANG/Week_4/Chapter8"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dcbkjZvu6ZUX","executionInfo":{"status":"ok","timestamp":1654925114992,"user_tz":-420,"elapsed":1996,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}},"outputId":"c4b2d643-2fac-4550-8763-0ae5d30f5ae2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/LDS8_K275_ONLINE_NGUYENTHIKIMHOANG/Week_4/Chapter8\n"]}]},{"cell_type":"code","source":[" import warnings \n"," warnings.filterwarnings('ignore')"],"metadata":{"id":"pAgsPNIz6hXv","executionInfo":{"status":"ok","timestamp":1654925114993,"user_tz":-420,"elapsed":4,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from IPython.display import Image, SVG \n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras import Model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D \n","from tensorflow.keras.layers import UpSampling2D, Flatten, Reshape \n","from tensorflow.keras import regularizers"],"metadata":{"id":"Q4Lq0Yl96mgm","executionInfo":{"status":"ok","timestamp":1654925116640,"user_tz":-420,"elapsed":1650,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Loads the training and test data sets (ignoring class labels)\n","(x_train, _), (x_test, _) = mnist.load_data()\n","# Scales the training and test data to range between 0 and 1.\n","max_value = float(x_train.max())\n","x_train = x_train.astype('float32') / max_value \n","x_test = x_test.astype('float32') / max_value"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EmdkuaJM6yQ3","executionInfo":{"status":"ok","timestamp":1654925118499,"user_tz":-420,"elapsed":1867,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}},"outputId":"042f9c66-7bdb-4526-b4be-2d58905cc2b0"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":[" x_train.shape, x_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-99d-ZMs61RJ","executionInfo":{"status":"ok","timestamp":1654925118500,"user_tz":-420,"elapsed":30,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}},"outputId":"6d5f6059-24a2-451a-bf74-3b3d717b1616"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((60000, 28, 28), (10000, 28, 28))"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["np.prod(x_train.shape[1:])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Mnx9Af563OU","executionInfo":{"status":"ok","timestamp":1654925118500,"user_tz":-420,"elapsed":24,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}},"outputId":"6a119dd5-3ccb-474d-9325-56b23ddd1699"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["784"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["x_train = x_train.reshape((len(x_train), 28, 28, 1))\n","x_test = x_test.reshape((len(x_test), 28, 28, 1))"],"metadata":{"id":"CIv0SdMX7Co2","executionInfo":{"status":"ok","timestamp":1654925237584,"user_tz":-420,"elapsed":5,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":[" (x_train.shape, x_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dci59aOS7Oez","executionInfo":{"status":"ok","timestamp":1654925238601,"user_tz":-420,"elapsed":6,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}},"outputId":"e29e0962-22bb-465c-8612-0265eb3f4f41"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((60000, 28, 28, 1), (10000, 28, 28, 1))"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# Deep Autoencoder\n","autoencoder = Sequential()\n","# Encoder Layers\n","autoencoder.add(Conv2D(16, (3, 3), activation='relu',\n","                       padding='same',\n","                       input_shape=x_train.shape[1:])) # [28,28]\n","autoencoder.add(MaxPooling2D((2, 2), padding='same')) #[14,14]\n","autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n","autoencoder.add(MaxPooling2D((2, 2), padding='same')) # [7, 7]\n","autoencoder.add(Conv2D(8, (3, 3), strides=(2,2),activation='relu', padding='same')) #[4,4]\n","# Flatten encoding for visualization\n","autoencoder.add(Flatten())\n","# https://keras.io/layers/core/\n","autoencoder.add(Reshape((4, 4, 8))) # Reshapes an output to a certain shape.\n","# Decoder Layers\n","autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n","# https://keras.io/layers/convolutional/\n","autoencoder.add(UpSampling2D((2, 2)))\n","autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n","autoencoder.add(UpSampling2D((2, 2)))\n","autoencoder.add(Conv2D(16, (3, 3), activation='relu'))\n","autoencoder.add(UpSampling2D((2, 2)))\n","autoencoder.add(Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\n","autoencoder.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"94W_dDSs7XP-","executionInfo":{"status":"ok","timestamp":1654925258880,"user_tz":-420,"elapsed":931,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}},"outputId":"86f6542f-7c7e-4405-d21f-f53e39541d28"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_2 (Conv2D)           (None, 28, 28, 16)        160       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 14, 14, 16)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 14, 14, 8)         1160      \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 7, 7, 8)          0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 4, 4, 8)           584       \n","                                                                 \n"," flatten (Flatten)           (None, 128)               0         \n","                                                                 \n"," reshape (Reshape)           (None, 4, 4, 8)           0         \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 4, 4, 8)           584       \n","                                                                 \n"," up_sampling2d (UpSampling2D  (None, 8, 8, 8)          0         \n"," )                                                               \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 8, 8, 8)           584       \n","                                                                 \n"," up_sampling2d_1 (UpSampling  (None, 16, 16, 8)        0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 14, 14, 16)        1168      \n","                                                                 \n"," up_sampling2d_2 (UpSampling  (None, 28, 28, 16)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 28, 28, 1)         145       \n","                                                                 \n","=================================================================\n","Total params: 4,385\n","Trainable params: 4,385\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# dense_1 = input*output + bias = 784 * 32 + 32 = 25120 # encode\n","# dense_2 = input*output + bias = 32 * 784 + 784 = 25872 # decode"],"metadata":{"id":"MjYrv4wu7kzH","executionInfo":{"status":"aborted","timestamp":1654925121965,"user_tz":-420,"elapsed":420,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Xem thử 784 đưa vào thì còn lại 32, xem xem 32 ở encoder là cái gì, ko thật cần thiết khi chạy mô hình\n","# Encoder Model\n","encoder = Model(inputs=autoencoder.input,\n","outputs = autoencoder.get_layer('flatten').output)\n","encoder.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dMy5xMI77ory","executionInfo":{"status":"ok","timestamp":1654925268076,"user_tz":-420,"elapsed":426,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}},"outputId":"5344f308-94e6-4bc3-f8e9-27e7144d1b3a"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_2_input (InputLayer)  [(None, 28, 28, 1)]      0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 28, 28, 16)        160       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 14, 14, 16)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 14, 14, 8)         1160      \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 7, 7, 8)          0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 4, 4, 8)           584       \n","                                                                 \n"," flatten (Flatten)           (None, 128)               0         \n","                                                                 \n","=================================================================\n","Total params: 1,904\n","Trainable params: 1,904\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["#autoencoder.compile(optimizer='adam', loss='binary_crossentropy') \n","# Unsupervised learning\n","#autoencoder.fit(x_train, x_train,\n","#                epochs=50,\n","#                batch_size=256,\n","#                shuffle=True, # xáo trộn dữ liệu huấn luyện mỗi epoch \n","#                validation_data=(x_test, x_test))"],"metadata":{"id":"WvtpbhDl7vxY","executionInfo":{"status":"ok","timestamp":1654925273614,"user_tz":-420,"elapsed":374,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# trong truong hop thuc thi lau, can co checkpoint\n","# define the checkpoint\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.callbacks import EarlyStopping\n","#set early stopping monitor so the model stops training when it won't improve any\n","early_stopping_monitor = EarlyStopping(patience=10)\n","filepath = \"cnn_auto_model.h5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='loss',\n","verbose=1,\n","\n","save_best_only=True,\n","mode='min')\n","\n","callbacks_list = [checkpoint, early_stopping_monitor]\n","# Train the model\n","# autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_siz\n","# epochs=epochs,verbose=1,validation_data=(va\n","autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n","autoencoder.fit(x_train, x_train,\n","epochs=100,\n","batch_size=128,\n","validation_data=(x_test, x_test),\n","callbacks=callbacks_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8U3HN4fQKbU9","executionInfo":{"status":"ok","timestamp":1654925645823,"user_tz":-420,"elapsed":369349,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}},"outputId":"4e1b91bd-f5e2-4b02-bf59-c56ccf2dfa64"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","469/469 [==============================] - ETA: 0s - loss: 0.2186\n","Epoch 1: loss improved from inf to 0.21862, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 17s 9ms/step - loss: 0.2186 - val_loss: 0.1387\n","Epoch 2/100\n","467/469 [============================>.] - ETA: 0s - loss: 0.1284\n","Epoch 2: loss improved from 0.21862 to 0.12836, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1284 - val_loss: 0.1191\n","Epoch 3/100\n","468/469 [============================>.] - ETA: 0s - loss: 0.1151\n","Epoch 3: loss improved from 0.12836 to 0.11506, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.1151 - val_loss: 0.1093\n","Epoch 4/100\n","467/469 [============================>.] - ETA: 0s - loss: 0.1082\n","Epoch 4: loss improved from 0.11506 to 0.10823, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.1082 - val_loss: 0.1050\n","Epoch 5/100\n","469/469 [==============================] - ETA: 0s - loss: 0.1045\n","Epoch 5: loss improved from 0.10823 to 0.10453, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.1045 - val_loss: 0.1018\n","Epoch 6/100\n","466/469 [============================>.] - ETA: 0s - loss: 0.1019\n","Epoch 6: loss improved from 0.10453 to 0.10193, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.1019 - val_loss: 0.1000\n","Epoch 7/100\n","466/469 [============================>.] - ETA: 0s - loss: 0.1000\n","Epoch 7: loss improved from 0.10193 to 0.09999, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.1000 - val_loss: 0.0983\n","Epoch 8/100\n","468/469 [============================>.] - ETA: 0s - loss: 0.0983\n","Epoch 8: loss improved from 0.09999 to 0.09827, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0983 - val_loss: 0.0969\n","Epoch 9/100\n","463/469 [============================>.] - ETA: 0s - loss: 0.0969\n","Epoch 9: loss improved from 0.09827 to 0.09687, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0969 - val_loss: 0.0949\n","Epoch 10/100\n","466/469 [============================>.] - ETA: 0s - loss: 0.0956\n","Epoch 10: loss improved from 0.09687 to 0.09561, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0956 - val_loss: 0.0942\n","Epoch 11/100\n","468/469 [============================>.] - ETA: 0s - loss: 0.0946\n","Epoch 11: loss improved from 0.09561 to 0.09456, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0946 - val_loss: 0.0926\n","Epoch 12/100\n","464/469 [============================>.] - ETA: 0s - loss: 0.0935\n","Epoch 12: loss improved from 0.09456 to 0.09350, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0935 - val_loss: 0.0920\n","Epoch 13/100\n","467/469 [============================>.] - ETA: 0s - loss: 0.0927\n","Epoch 13: loss improved from 0.09350 to 0.09265, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0926 - val_loss: 0.0910\n","Epoch 14/100\n","468/469 [============================>.] - ETA: 0s - loss: 0.0919\n","Epoch 14: loss improved from 0.09265 to 0.09185, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0919 - val_loss: 0.0905\n","Epoch 15/100\n","463/469 [============================>.] - ETA: 0s - loss: 0.0911\n","Epoch 15: loss improved from 0.09185 to 0.09113, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0911 - val_loss: 0.0902\n","Epoch 16/100\n","468/469 [============================>.] - ETA: 0s - loss: 0.0905\n","Epoch 16: loss improved from 0.09113 to 0.09047, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0905 - val_loss: 0.0896\n","Epoch 17/100\n","463/469 [============================>.] - ETA: 0s - loss: 0.0901\n","Epoch 17: loss improved from 0.09047 to 0.09007, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0901 - val_loss: 0.0885\n","Epoch 18/100\n","468/469 [============================>.] - ETA: 0s - loss: 0.0895\n","Epoch 18: loss improved from 0.09007 to 0.08953, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0895 - val_loss: 0.0880\n","Epoch 19/100\n","467/469 [============================>.] - ETA: 0s - loss: 0.0891\n","Epoch 19: loss improved from 0.08953 to 0.08905, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0891 - val_loss: 0.0878\n","Epoch 20/100\n","462/469 [============================>.] - ETA: 0s - loss: 0.0887\n","Epoch 20: loss improved from 0.08905 to 0.08867, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0887 - val_loss: 0.0872\n","Epoch 21/100\n","465/469 [============================>.] - ETA: 0s - loss: 0.0883\n","Epoch 21: loss improved from 0.08867 to 0.08827, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0883 - val_loss: 0.0870\n","Epoch 22/100\n","466/469 [============================>.] - ETA: 0s - loss: 0.0879\n","Epoch 22: loss improved from 0.08827 to 0.08790, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0879 - val_loss: 0.0870\n","Epoch 23/100\n","463/469 [============================>.] - ETA: 0s - loss: 0.0876\n","Epoch 23: loss improved from 0.08790 to 0.08759, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0876 - val_loss: 0.0863\n","Epoch 24/100\n","467/469 [============================>.] - ETA: 0s - loss: 0.0873\n","Epoch 24: loss improved from 0.08759 to 0.08727, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0873 - val_loss: 0.0862\n","Epoch 25/100\n","469/469 [==============================] - ETA: 0s - loss: 0.0869\n","Epoch 25: loss improved from 0.08727 to 0.08695, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0869 - val_loss: 0.0857\n","Epoch 26/100\n","462/469 [============================>.] - ETA: 0s - loss: 0.0867\n","Epoch 26: loss improved from 0.08695 to 0.08671, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0867 - val_loss: 0.0859\n","Epoch 27/100\n","468/469 [============================>.] - ETA: 0s - loss: 0.0865\n","Epoch 27: loss improved from 0.08671 to 0.08647, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0865 - val_loss: 0.0859\n","Epoch 28/100\n","466/469 [============================>.] - ETA: 0s - loss: 0.0862\n","Epoch 28: loss improved from 0.08647 to 0.08621, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0862 - val_loss: 0.0849\n","Epoch 29/100\n","462/469 [============================>.] - ETA: 0s - loss: 0.0860\n","Epoch 29: loss improved from 0.08621 to 0.08602, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0860 - val_loss: 0.0849\n","Epoch 30/100\n","468/469 [============================>.] - ETA: 0s - loss: 0.0859\n","Epoch 30: loss improved from 0.08602 to 0.08587, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0859 - val_loss: 0.0850\n","Epoch 31/100\n","469/469 [==============================] - ETA: 0s - loss: 0.0856\n","Epoch 31: loss improved from 0.08587 to 0.08559, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0856 - val_loss: 0.0844\n","Epoch 32/100\n","464/469 [============================>.] - ETA: 0s - loss: 0.0854\n","Epoch 32: loss improved from 0.08559 to 0.08541, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0854 - val_loss: 0.0842\n","Epoch 33/100\n","462/469 [============================>.] - ETA: 0s - loss: 0.0853\n","Epoch 33: loss improved from 0.08541 to 0.08528, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0853 - val_loss: 0.0841\n","Epoch 34/100\n","463/469 [============================>.] - ETA: 0s - loss: 0.0851\n","Epoch 34: loss improved from 0.08528 to 0.08510, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0851 - val_loss: 0.0840\n","Epoch 35/100\n","466/469 [============================>.] - ETA: 0s - loss: 0.0850\n","Epoch 35: loss improved from 0.08510 to 0.08496, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0850 - val_loss: 0.0838\n","Epoch 36/100\n","469/469 [==============================] - ETA: 0s - loss: 0.0848\n","Epoch 36: loss improved from 0.08496 to 0.08483, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0848 - val_loss: 0.0836\n","Epoch 37/100\n","463/469 [============================>.] - ETA: 0s - loss: 0.0846\n","Epoch 37: loss improved from 0.08483 to 0.08464, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0846 - val_loss: 0.0837\n","Epoch 38/100\n","465/469 [============================>.] - ETA: 0s - loss: 0.0846\n","Epoch 38: loss improved from 0.08464 to 0.08461, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0846 - val_loss: 0.0834\n","Epoch 39/100\n","466/469 [============================>.] - ETA: 0s - loss: 0.0844\n","Epoch 39: loss improved from 0.08461 to 0.08443, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0844 - val_loss: 0.0832\n","Epoch 40/100\n","464/469 [============================>.] - ETA: 0s - loss: 0.0843\n","Epoch 40: loss improved from 0.08443 to 0.08430, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0843 - val_loss: 0.0831\n","Epoch 41/100\n","465/469 [============================>.] - ETA: 0s - loss: 0.0842\n","Epoch 41: loss improved from 0.08430 to 0.08424, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0842 - val_loss: 0.0832\n","Epoch 42/100\n","465/469 [============================>.] - ETA: 0s - loss: 0.0841\n","Epoch 42: loss improved from 0.08424 to 0.08408, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0841 - val_loss: 0.0830\n","Epoch 43/100\n","466/469 [============================>.] - ETA: 0s - loss: 0.0840\n","Epoch 43: loss improved from 0.08408 to 0.08399, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0840 - val_loss: 0.0829\n","Epoch 44/100\n","469/469 [==============================] - ETA: 0s - loss: 0.0839\n","Epoch 44: loss improved from 0.08399 to 0.08387, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0839 - val_loss: 0.0830\n","Epoch 45/100\n","464/469 [============================>.] - ETA: 0s - loss: 0.0838\n","Epoch 45: loss improved from 0.08387 to 0.08377, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0838 - val_loss: 0.0826\n","Epoch 46/100\n","462/469 [============================>.] - ETA: 0s - loss: 0.0836\n","Epoch 46: loss improved from 0.08377 to 0.08365, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0836 - val_loss: 0.0827\n","Epoch 47/100\n","463/469 [============================>.] - ETA: 0s - loss: 0.0836\n","Epoch 47: loss improved from 0.08365 to 0.08362, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0836 - val_loss: 0.0825\n","Epoch 48/100\n","469/469 [==============================] - ETA: 0s - loss: 0.0835\n","Epoch 48: loss improved from 0.08362 to 0.08353, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0835 - val_loss: 0.0823\n","Epoch 49/100\n","462/469 [============================>.] - ETA: 0s - loss: 0.0834\n","Epoch 49: loss improved from 0.08353 to 0.08336, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0834 - val_loss: 0.0824\n","Epoch 50/100\n","463/469 [============================>.] - ETA: 0s - loss: 0.0834\n","Epoch 50: loss improved from 0.08336 to 0.08336, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0834 - val_loss: 0.0822\n","Epoch 51/100\n","469/469 [==============================] - ETA: 0s - loss: 0.0833\n","Epoch 51: loss improved from 0.08336 to 0.08333, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0833 - val_loss: 0.0822\n","Epoch 52/100\n","463/469 [============================>.] - ETA: 0s - loss: 0.0832\n","Epoch 52: loss improved from 0.08333 to 0.08318, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0832 - val_loss: 0.0820\n","Epoch 53/100\n","469/469 [==============================] - ETA: 0s - loss: 0.0831\n","Epoch 53: loss improved from 0.08318 to 0.08308, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 9ms/step - loss: 0.0831 - val_loss: 0.0820\n","Epoch 54/100\n","468/469 [============================>.] - ETA: 0s - loss: 0.0831\n","Epoch 54: loss did not improve from 0.08308\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0831 - val_loss: 0.0819\n","Epoch 55/100\n","462/469 [============================>.] - ETA: 0s - loss: 0.0829\n","Epoch 55: loss improved from 0.08308 to 0.08294, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0829 - val_loss: 0.0819\n","Epoch 56/100\n","466/469 [============================>.] - ETA: 0s - loss: 0.0829\n","Epoch 56: loss improved from 0.08294 to 0.08289, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0829 - val_loss: 0.0817\n","Epoch 57/100\n","469/469 [==============================] - ETA: 0s - loss: 0.0829\n","Epoch 57: loss improved from 0.08289 to 0.08287, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0829 - val_loss: 0.0819\n","Epoch 58/100\n","462/469 [============================>.] - ETA: 0s - loss: 0.0827\n","Epoch 58: loss improved from 0.08287 to 0.08273, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0827 - val_loss: 0.0817\n","Epoch 59/100\n","466/469 [============================>.] - ETA: 0s - loss: 0.0827\n","Epoch 59: loss improved from 0.08273 to 0.08269, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0827 - val_loss: 0.0816\n","Epoch 60/100\n","467/469 [============================>.] - ETA: 0s - loss: 0.0826\n","Epoch 60: loss improved from 0.08269 to 0.08262, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0826 - val_loss: 0.0815\n","Epoch 61/100\n","462/469 [============================>.] - ETA: 0s - loss: 0.0826\n","Epoch 61: loss improved from 0.08262 to 0.08257, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0826 - val_loss: 0.0814\n","Epoch 62/100\n","462/469 [============================>.] - ETA: 0s - loss: 0.0825\n","Epoch 62: loss improved from 0.08257 to 0.08250, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0825 - val_loss: 0.0827\n","Epoch 63/100\n","463/469 [============================>.] - ETA: 0s - loss: 0.0825\n","Epoch 63: loss improved from 0.08250 to 0.08246, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0825 - val_loss: 0.0816\n","Epoch 64/100\n","466/469 [============================>.] - ETA: 0s - loss: 0.0824\n","Epoch 64: loss improved from 0.08246 to 0.08238, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0824 - val_loss: 0.0813\n","Epoch 65/100\n","467/469 [============================>.] - ETA: 0s - loss: 0.0824\n","Epoch 65: loss did not improve from 0.08238\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0824 - val_loss: 0.0815\n","Epoch 66/100\n","464/469 [============================>.] - ETA: 0s - loss: 0.0823\n","Epoch 66: loss improved from 0.08238 to 0.08226, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0823 - val_loss: 0.0813\n","Epoch 67/100\n","463/469 [============================>.] - ETA: 0s - loss: 0.0822\n","Epoch 67: loss improved from 0.08226 to 0.08219, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0822 - val_loss: 0.0812\n","Epoch 68/100\n","468/469 [============================>.] - ETA: 0s - loss: 0.0822\n","Epoch 68: loss did not improve from 0.08219\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0822 - val_loss: 0.0812\n","Epoch 69/100\n","469/469 [==============================] - ETA: 0s - loss: 0.0821\n","Epoch 69: loss improved from 0.08219 to 0.08214, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0821 - val_loss: 0.0812\n","Epoch 70/100\n","469/469 [==============================] - ETA: 0s - loss: 0.0821\n","Epoch 70: loss improved from 0.08214 to 0.08205, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0821 - val_loss: 0.0810\n","Epoch 71/100\n","468/469 [============================>.] - ETA: 0s - loss: 0.0820\n","Epoch 71: loss improved from 0.08205 to 0.08205, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0821 - val_loss: 0.0810\n","Epoch 72/100\n","462/469 [============================>.] - ETA: 0s - loss: 0.0820\n","Epoch 72: loss improved from 0.08205 to 0.08199, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0820 - val_loss: 0.0808\n","Epoch 73/100\n","466/469 [============================>.] - ETA: 0s - loss: 0.0819\n","Epoch 73: loss improved from 0.08199 to 0.08194, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0819 - val_loss: 0.0815\n","Epoch 74/100\n","466/469 [============================>.] - ETA: 0s - loss: 0.0819\n","Epoch 74: loss improved from 0.08194 to 0.08187, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0819 - val_loss: 0.0809\n","Epoch 75/100\n","467/469 [============================>.] - ETA: 0s - loss: 0.0819\n","Epoch 75: loss improved from 0.08187 to 0.08186, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0819 - val_loss: 0.0810\n","Epoch 76/100\n","465/469 [============================>.] - ETA: 0s - loss: 0.0818\n","Epoch 76: loss improved from 0.08186 to 0.08181, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0818 - val_loss: 0.0808\n","Epoch 77/100\n","462/469 [============================>.] - ETA: 0s - loss: 0.0817\n","Epoch 77: loss improved from 0.08181 to 0.08175, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0817 - val_loss: 0.0811\n","Epoch 78/100\n","462/469 [============================>.] - ETA: 0s - loss: 0.0818\n","Epoch 78: loss did not improve from 0.08175\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0818 - val_loss: 0.0813\n","Epoch 79/100\n","462/469 [============================>.] - ETA: 0s - loss: 0.0817\n","Epoch 79: loss improved from 0.08175 to 0.08166, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0817 - val_loss: 0.0807\n","Epoch 80/100\n","463/469 [============================>.] - ETA: 0s - loss: 0.0816\n","Epoch 80: loss improved from 0.08166 to 0.08159, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0816 - val_loss: 0.0810\n","Epoch 81/100\n","464/469 [============================>.] - ETA: 0s - loss: 0.0816\n","Epoch 81: loss did not improve from 0.08159\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0816 - val_loss: 0.0809\n","Epoch 82/100\n","464/469 [============================>.] - ETA: 0s - loss: 0.0816\n","Epoch 82: loss did not improve from 0.08159\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0816 - val_loss: 0.0805\n","Epoch 83/100\n","466/469 [============================>.] - ETA: 0s - loss: 0.0815\n","Epoch 83: loss improved from 0.08159 to 0.08151, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0815 - val_loss: 0.0804\n","Epoch 84/100\n","469/469 [==============================] - ETA: 0s - loss: 0.0815\n","Epoch 84: loss improved from 0.08151 to 0.08148, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0815 - val_loss: 0.0806\n","Epoch 85/100\n","469/469 [==============================] - ETA: 0s - loss: 0.0814\n","Epoch 85: loss improved from 0.08148 to 0.08142, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0814 - val_loss: 0.0806\n","Epoch 86/100\n","466/469 [============================>.] - ETA: 0s - loss: 0.0814\n","Epoch 86: loss improved from 0.08142 to 0.08140, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0814 - val_loss: 0.0805\n","Epoch 87/100\n","463/469 [============================>.] - ETA: 0s - loss: 0.0814\n","Epoch 87: loss did not improve from 0.08140\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0814 - val_loss: 0.0804\n","Epoch 88/100\n","464/469 [============================>.] - ETA: 0s - loss: 0.0813\n","Epoch 88: loss improved from 0.08140 to 0.08133, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0813 - val_loss: 0.0803\n","Epoch 89/100\n","468/469 [============================>.] - ETA: 0s - loss: 0.0813\n","Epoch 89: loss improved from 0.08133 to 0.08129, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0813 - val_loss: 0.0809\n","Epoch 90/100\n","467/469 [============================>.] - ETA: 0s - loss: 0.0812\n","Epoch 90: loss improved from 0.08129 to 0.08122, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0812 - val_loss: 0.0807\n","Epoch 91/100\n","464/469 [============================>.] - ETA: 0s - loss: 0.0813\n","Epoch 91: loss did not improve from 0.08122\n","469/469 [==============================] - 3s 7ms/step - loss: 0.0812 - val_loss: 0.0802\n","Epoch 92/100\n","467/469 [============================>.] - ETA: 0s - loss: 0.0812\n","Epoch 92: loss improved from 0.08122 to 0.08117, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0812 - val_loss: 0.0804\n","Epoch 93/100\n","465/469 [============================>.] - ETA: 0s - loss: 0.0811\n","Epoch 93: loss improved from 0.08117 to 0.08115, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0811 - val_loss: 0.0802\n","Epoch 94/100\n","468/469 [============================>.] - ETA: 0s - loss: 0.0811\n","Epoch 94: loss improved from 0.08115 to 0.08113, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0811 - val_loss: 0.0803\n","Epoch 95/100\n","467/469 [============================>.] - ETA: 0s - loss: 0.0811\n","Epoch 95: loss improved from 0.08113 to 0.08105, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0811 - val_loss: 0.0802\n","Epoch 96/100\n","469/469 [==============================] - ETA: 0s - loss: 0.0810\n","Epoch 96: loss improved from 0.08105 to 0.08103, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0810 - val_loss: 0.0799\n","Epoch 97/100\n","463/469 [============================>.] - ETA: 0s - loss: 0.0810\n","Epoch 97: loss improved from 0.08103 to 0.08101, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0810 - val_loss: 0.0801\n","Epoch 98/100\n","467/469 [============================>.] - ETA: 0s - loss: 0.0810\n","Epoch 98: loss improved from 0.08101 to 0.08100, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0810 - val_loss: 0.0803\n","Epoch 99/100\n","466/469 [============================>.] - ETA: 0s - loss: 0.0809\n","Epoch 99: loss improved from 0.08100 to 0.08090, saving model to cnn_auto_model.h5\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0809 - val_loss: 0.0800\n","Epoch 100/100\n","465/469 [============================>.] - ETA: 0s - loss: 0.0809\n","Epoch 100: loss did not improve from 0.08090\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0809 - val_loss: 0.0800\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7efb065895d0>"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["num_images = 10\n","np.random.seed(42)\n","random_test_images = np.random.randint(x_test.shape[0], size=num_images) # trong\n","\n","encoded_imgs = encoder.predict(x_test) \n","decoded_imgs = autoencoder.predict(x_test)"],"metadata":{"id":"3w6ERcf_73Ac","executionInfo":{"status":"ok","timestamp":1654929952406,"user_tz":-420,"elapsed":2535,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(18, 4))\n","for i, image_idx in enumerate(random_test_images):\n","  # plot original image\n","  ax = plt.subplot(3, num_images, i + 1) # in hinh tren dong 1 plt.imshow(x_test[image_idx].reshape(28, 28)) # tra lai hinh dang ban dau ch plt.gray()\n","  ax.get_xaxis().set_visible(False)\n","  ax.get_yaxis().set_visible(False)\n","  # plot encoded image\n","  ax = plt.subplot(3, num_images, num_images + i + 1) # in hinh tren dong 2 plt.imshow(encoded_imgs[image_idx].reshape(8, 4)) # hinh dang co chai 8 * 4 plt.gray()\n","  ax.get_xaxis().set_visible(False)\n","  ax.get_yaxis().set_visible(False)\n","  # plot reconstructed image\n","  ax = plt.subplot(3, num_images, 2*num_images + i + 1) # in hinh tren dong 3 plt.imshow(decoded_imgs[image_idx].reshape(28, 28)) # tra lai hinh dang cua plt.gray()\n","  ax.get_xaxis().set_visible(False)\n","  ax.get_yaxis().set_visible(False)\n","plt.show()"],"metadata":{"id":"LPq-x2-77-xf","colab":{"base_uri":"https://localhost:8080/","height":163},"executionInfo":{"status":"ok","timestamp":1654929956003,"user_tz":-420,"elapsed":1185,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}},"outputId":"467b3505-9766-4088-f273-7d7a4ef504ac"},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1296x288 with 30 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# save model\n","autoencoder.save('decoder_cnn.h5') \n","#print(\"save!!!\")"],"metadata":{"id":"weyhfboC8GaD","executionInfo":{"status":"ok","timestamp":1654929962969,"user_tz":-420,"elapsed":522,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":[" encoder.save('encoder_cnn.h5')"],"metadata":{"id":"8QRQjR838IZR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654929975847,"user_tz":-420,"elapsed":382,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}},"outputId":"f0cb5209-0cc2-4294-a8e8-2683609e56c7"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]}]},{"cell_type":"code","source":["# o mot noi nao do...\n","# Predicting on Test Data, model load from file \n","from tensorflow.keras.models import load_model \n","encoder = load_model('encoder_cnn.h5')\n","decoder = load_model('decoder_cnn.h5')"],"metadata":{"id":"Lkf337BB8Kn7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654929979056,"user_tz":-420,"elapsed":1091,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}},"outputId":"3657592f-a150-4b2a-8154-2cdaa4736359"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]}]},{"cell_type":"code","source":["num_images = 5\n","np.random.seed(42)\n","random_test_images = np.random.randint(x_test.shape[0], size=num_images)\n","\n","encoded_imgs = encoder.predict(x_test) \n","decoded_imgs = decoder.predict(x_test)"],"metadata":{"id":"aRVHb1Js8SBm","colab":{"base_uri":"https://localhost:8080/","height":198},"executionInfo":{"status":"error","timestamp":1654929966058,"user_tz":-420,"elapsed":1363,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}},"outputId":"2993ce64-61ff-4111-c1ad-812f09f9be28"},"execution_count":24,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-d679d2f4301d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mencoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdecoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'decoder' is not defined"]}]},{"cell_type":"code","source":["plt.figure(figsize=(18, 4))\n","for i, image_idx in enumerate(random_test_images):\n","  # plot original image\n","  ax = plt.subplot(3, num_images, i + 1) \n","  plt.imshow(x_test[image_idx].reshape(28, 28)) \n","  plt.gray()\n","  ax.get_xaxis().set_visible(False) \n","  ax.get_yaxis().set_visible(False)\n","  # plot encoded image\n","  ax = plt.subplot(3, num_images, num_images + i + 1) \n","  plt.imshow(encoded_imgs[image_idx].reshape(8, 4)) \n","  plt.gray()\n","  ax.get_xaxis().set_visible(False) \n","  ax.get_yaxis().set_visible(False)\n","  # plot reconstructed image\n","  ax = plt.subplot(3, num_images, 2*num_images + i + 1) \n","  plt.imshow(decoded_imgs[image_idx].reshape(28, 28)) \n","  plt.gray()\n","  ax.get_xaxis().set_visible(False) \n","  ax.get_yaxis().set_visible(False)\n","plt.show()"],"metadata":{"id":"cQNQSyh88WOE","executionInfo":{"status":"aborted","timestamp":1654925121973,"user_tz":-420,"elapsed":425,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" # Link: # https://ramhiser.com/post/2018-05-14-autoencoders-with-keras/"],"metadata":{"id":"ahFU83c_8ejI","executionInfo":{"status":"aborted","timestamp":1654925121973,"user_tz":-420,"elapsed":17,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, image_idx in enumerate(random_test_images):\n","  # plot reconstructed image \n","  plt.imshow(decoded_imgs[image_idx].reshape(28, 28)) \n","  plt.gray()\n","  image_name = \"demo_CNN/image_\" + str(image_idx) + \".jpg\" \n","  plt.savefig(image_name)\n","  plt.show()"],"metadata":{"id":"go3ZnjAb8iPx","executionInfo":{"status":"aborted","timestamp":1654925121974,"user_tz":-420,"elapsed":17,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}}},"execution_count":null,"outputs":[]}]}