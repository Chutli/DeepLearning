{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"demo_fashion_gans.ipynb","provenance":[],"authorship_tag":"ABX9TyN73HiZqJw0lz4xAoPxB+aT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Chapter 11: GANs - FASHION"],"metadata":{"id":"kB_SLoIK9Fnp"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"nEo2C1xiWEBR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655426912362,"user_tz":-420,"elapsed":18682,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}},"outputId":"d268a60d-4bb3-43e9-d460-abd530f5ef18"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/LDS8_K275_ONLINE_NGUYENTHIKIMHOANG/Week_5/Chapter11"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hyL2Bhsm9dL4","executionInfo":{"status":"ok","timestamp":1655426912902,"user_tz":-420,"elapsed":545,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}},"outputId":"9c9cbbf2-b209-411b-8b51-d8e66b0b2931"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/LDS8_K275_ONLINE_NGUYENTHIKIMHOANG/Week_5/Chapter11\n"]}]},{"cell_type":"code","source":["# pip install tqdm\n","import numpy as np\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt"],"metadata":{"id":"8tR2qnHb9WLz","executionInfo":{"status":"ok","timestamp":1655426912903,"user_tz":-420,"elapsed":7,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.layers import Input\n","from tensorflow.keras import Model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Reshape, Dense, Dropout, Flatten, LeakyReLU\n","from tensorflow.keras.layers import Convolution2D, UpSampling2D\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.datasets import mnist, fashion_mnist\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import backend as K\n","from tensorflow.keras import initializers"],"metadata":{"id":"XjYZyzUc9cxZ","executionInfo":{"status":"ok","timestamp":1655426915770,"user_tz":-420,"elapsed":2871,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Deterministic output.\n","# Tired of seeing the same results every time? Remove the line below.\n","np.random.seed(1000)\n","# The results are a little better when the dimensionality of the random vector is\n","# The dimensionality has been left at 100 for consistency with other GAN implemen\n","random_dim = 100"],"metadata":{"id":"dbY9p0N19gX7","executionInfo":{"status":"ok","timestamp":1655426915771,"user_tz":-420,"elapsed":14,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Load MNIST data\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","X_train = (X_train.astype(np.float32) - 127.5)/127.5\n","X_train = X_train.reshape(60000, 784)"],"metadata":{"id":"_w05_97S9tIY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655426916408,"user_tz":-420,"elapsed":647,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}},"outputId":"6102209a-7bb1-4233-9f6d-1b06d5ba2137"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["# viet lai duoi dang function doc du lieu\n","def load_minst_data():\n"," # load the data\n"," (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n"," # normalize our inputs to be in the range[-1, 1]\n"," x_train = (x_train.astype(np.float32) - 127.5)/127.5\n"," # convert x_train with a shape of (60000, 28, 28) to (60000, 784) so we have\n"," # 784 columns per row\n"," x_train = x_train.reshape(60000, 784)\n"," return (x_train, y_train, x_test, y_test)\n"],"metadata":{"id":"t8WSVk019yWf","executionInfo":{"status":"ok","timestamp":1655426916409,"user_tz":-420,"elapsed":17,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# You will use the Adam optimizer\n","def get_optimizer():\n"," return Adam(lr=0.0002, beta_1=0.5)"],"metadata":{"id":"iHKeJcHs913H","executionInfo":{"status":"ok","timestamp":1655426916409,"user_tz":-420,"elapsed":16,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def get_generator(optimizer):\n"," generator = Sequential()\n"," generator.add(Dense(256, \n","                     input_dim=random_dim, \n","                     kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n"," generator.add(LeakyReLU(0.2)) #https://en.wikipedia.org/wiki/Rectifier_(neura\n"," \n"," generator.add(Dense(512))\n"," generator.add(LeakyReLU(0.2))\n"," \n"," generator.add(Dense(1024))\n"," generator.add(LeakyReLU(0.2))\n"," \n"," generator.add(Dense(784, activation='tanh'))\n"," generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n"," return generator\n"],"metadata":{"id":"-oxpl4HP94TH","executionInfo":{"status":"ok","timestamp":1655426916409,"user_tz":-420,"elapsed":15,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def get_discriminator(optimizer):\n"," discriminator = Sequential()\n"," discriminator.add(Dense(1024, \n","                   input_dim=784, \n","                   kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n"," \n"," discriminator.add(LeakyReLU(0.2))\n"," discriminator.add(Dropout(0.3))\n"," \n"," discriminator.add(Dense(512))\n"," discriminator.add(LeakyReLU(0.2))\n"," discriminator.add(Dropout(0.3))\n"," \n"," discriminator.add(Dense(256))\n"," discriminator.add(LeakyReLU(0.2))\n"," discriminator.add(Dropout(0.3))\n"," \n"," discriminator.add(Dense(1, activation='sigmoid'))\n"," discriminator.compile(loss='binary_crossentropy', optimizer=optimizer)\n"," return discriminator"],"metadata":{"id":"uvymMFjr-YER","executionInfo":{"status":"ok","timestamp":1655426916410,"user_tz":-420,"elapsed":16,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def get_gan_network(discriminator, random_dim, generator, optimizer):\n"," # We initially set trainable to False \n"," # since we only want to train either the generator or discriminator at a time\n"," discriminator.trainable = False\n"," # gan input (noise) will be 100-dimensional vectors\n"," gan_input = Input(shape=(random_dim,)) \n"," # the output of the generator (an image)\n"," x = generator(gan_input)\n"," # get the output of the discriminator (probability if the image is real or no\n"," gan_output = discriminator(x)\n"," gan = Model(inputs=gan_input, outputs=gan_output)\n"," gan.compile(loss='binary_crossentropy', optimizer=optimizer)\n"," return gan"],"metadata":{"id":"s6ZKB61z-idY","executionInfo":{"status":"ok","timestamp":1655426916410,"user_tz":-420,"elapsed":15,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Create a wall of generated MNIST images\n","def plot_generated_images(epoch, generator, examples=100, dim=(10, 10), figsize=(10,10)):\n","  noise = np.random.normal(0, 1, size=[examples, random_dim]) #random dim=100\n","  generated_images = generator.predict(noise)\n","  generated_images = generated_images.reshape(examples, 28, 28)\n"," \n","  plt.figure(figsize=figsize)\n","  for i in range(generated_images.shape[0]):\n","    plt.subplot(dim[0], dim[1], i+1)\n","    plt.imshow(generated_images[i], interpolation='nearest', cmap='gray_r')\n","    plt.axis('off') \n","    plt.tight_layout()\n","    plt.savefig('fashion_mnist/gan_generated_image_epoch_%d.png' % epoch)"],"metadata":{"id":"H0fmv8G5-k8w","executionInfo":{"status":"ok","timestamp":1655426953621,"user_tz":-420,"elapsed":7,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def train(epochs=1, batch_size=128):\n","  # Get the training and testing data\n","  x_train, y_train, x_test, y_test = load_minst_data()\n","  # Split the training data into batches of size 128\n","  batch_count = x_train.shape[0] / batch_size\n","\n","  # Build our GAN netowrk\n","  adam = get_optimizer()\n","  generator = get_generator(adam)\n","  discriminator = get_discriminator(adam)\n","  gan = get_gan_network(discriminator, random_dim, generator, adam)\n","\n","  for e in range(1, epochs+1):\n","    print('-'*15, 'Epoch %d' % e, '-'*15)\n","    # tao thanh process bar: https://tqdm.github.io/\n","    for _ in tqdm(range(int(batch_count))): \n","      # Get a random set of input noise and images\n","      noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n","      image_batch = x_train[np.random.randint(0, x_train.shape[0], size=batch_size)]\n","\n","      # Generate fake MNIST images\n","      generated_images = generator.predict(noise)\n","      X = np.concatenate([image_batch, generated_images])\n","\n","      # Labels for generated and real data\n","      y_dis = np.zeros(2*batch_size)\n","\n","      # One-sided label smoothing\n","      y_dis[:batch_size] = 0.9\n","\n","      # Train discriminator\n","      discriminator.trainable = True\n","      discriminator.train_on_batch(X, y_dis)\n","\n","      # Train generator\n","      noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n","      y_gen = np.ones(batch_size)\n","      discriminator.trainable = False\n","      gan.train_on_batch(noise, y_gen)\n","\n","    if e == 1 or e % 20 == 0:\n","      plot_generated_images(e, generator)\n","# in ket qua ra file: # save_generated_images(e, generator)"],"metadata":{"id":"Kdf9x-ER-tQ_","executionInfo":{"status":"ok","timestamp":1655426991152,"user_tz":-420,"elapsed":2468,"user":{"displayName":"Justina Nguyen","userId":"16459124056424385531"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["train(200, 128) # chay epoch = 200, batch = 128"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U9lLPayO_KWo","outputId":"237df3a1-288e-40a3-d06f-355b28a3e775"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 1 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:39<00:00, 11.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 2 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:33<00:00, 14.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 3 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:32<00:00, 14.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 4 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:30<00:00, 15.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 5 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:30<00:00, 15.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 6 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:28<00:00, 16.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 7 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:29<00:00, 15.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 8 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:29<00:00, 15.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 9 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:28<00:00, 16.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 10 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:29<00:00, 15.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 11 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:29<00:00, 15.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 12 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:30<00:00, 15.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 13 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:29<00:00, 15.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 14 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:29<00:00, 15.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 15 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:30<00:00, 15.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 16 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:30<00:00, 15.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 17 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:29<00:00, 15.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 18 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:29<00:00, 15.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 19 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:31<00:00, 15.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 20 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:29<00:00, 15.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 21 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:29<00:00, 15.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 22 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:29<00:00, 15.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 23 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:29<00:00, 15.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 24 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:30<00:00, 15.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 25 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:30<00:00, 15.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 26 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:31<00:00, 14.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 27 ---------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 468/468 [00:32<00:00, 14.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--------------- Epoch 28 ---------------\n"]},{"output_type":"stream","name":"stderr","text":[" 99%|█████████▊| 462/468 [00:32<00:00, 13.86it/s]"]}]},{"cell_type":"code","source":["# In progress bar\n","from tqdm import tqdm\n","from time import sleep"],"metadata":{"id":"cqD0z5jr_LVt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in tqdm(range(10000)):\n"," #...\n"," pass"],"metadata":{"id":"L2Z7fmoR_Na4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pbar = tqdm(total=100)\n","for i in range(10):\n"," sleep(0.1)\n"," pbar.update(10)\n","pbar.close()"],"metadata":{"id":"Th9wfXsF_RHn"},"execution_count":null,"outputs":[]}]}